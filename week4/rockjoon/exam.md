## 1

>한 빅 데이터 분석 회사는 Amazon S3 버킷에 데이터와 로그 파일을 write합니다. 이제 회사는 기존 데이터 파일과 진행 중인 파일 업데이트를 Amazon S3에서 Amazon Kinesis Data Streams로 스트리밍하려고 합니다.
솔루션 아키텍트로서 다음 중 이 요구 사항에 대한 솔루션을 구축하는 가장 빠른 방법으로 제안할 수 있는 것은 무엇일까요?
- A. Amazon S3에서 버킷 작업에 대한 CloudWatch 이벤트를 구성합니다. 그런 다음 필요한 데이터를 Amazon Kinesis Data Streams로 보내는 CloudWatch 이벤트에서 AWS Lambda 함수를 트리거할 수 있습니다.
- B. Amazon S3 버킷 작업은 Amazon Simple Notification Service(SNS)에 데이터를 쓰도록 직접 구성할 수 있습니다. 그런 다음 SNS를 사용하여 Amazon Kinesis Data Streams에 업데이트를 보낼 수 있습니다.
- C. S4 이벤트 알림을 활용하여 파일 생성 이벤트에 대한 Lambda 함수를 트리거합니다. 그러면 Lambda 함수가 필요한 데이터를 Amazon Kinesis Data Streams로 보냅니다.
- D. AWS Database Migration Service(AWS DMS)를 Amazon S3와 Amazon Kinesis Data Streams 간의 다리 역할로 활용합니다.

## 요구사항
* 기존에는 S3 버킷에 데이터를 write
* 이를 S3에서 Amazon Kinesis Data Streams 로 이전해야함.
* 가장 빠른 방법

## 풀이

정답 D

### AWS Database Migration Service(AWS DMS)
* 지원되는 소스에서 관계형 데이터베이스, 데이터 웨어하우스, 스트리밍 플랫폼 및 AWS 클라우드의 기타 데이터 스토리지로 데이터를 원활하게 마이그레이션
* 복잡한 구성이나 코드 개발 없이 즉시 작업 수행 가능
* DMS는 소스로 S3를 지원하고, 타겟으로 Kinesis Data Stream을 지원

## 2

>선도적인 온라인 게임 회사는 자사의 온라인 게임을 전 세계 사용자에게 제공하기 위해 주력 애플리케이션을 AWS 클라우드로 마이그레이션하고 있습니다. 이 회사는 Network Load Balancer, NLB (네트워크 로드 밸런서)를 사용하여 초당 수백만 건의 요청을 처리하려고 합니다. 엔지니어링 팀은 퍼블릭 서브넷에 여러 인스턴스를 프로비저닝하고 이러한 인스턴스 ID를 NLB의 대상으로 지정했습니다.
솔루션 아키텍트로서 엔지니어링 팀이 이러한 대상 인스턴스에 대한 올바른 라우팅 메커니즘을 이해하도록 도울 수 있을까요?
- 트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 Elastic IP 주소를 사용하여 인스턴스로 라우팅됩니다.
- 트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 프라이빗 IP 주소를 사용하여 인스턴스로 라우팅됩니다.
- 트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 공용 IP 주소를 사용하여 인스턴스로 라우팅됩니다.
- 트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 인스턴스 ID를 사용하여 인스턴스로 라우팅됩니다.

## 요구사항
* NLB를 사용하여 초당 수백만 건의 요청을 처리
* 퍼블릭 서브넷에 여러 인스턴스를 프로비저닝하고 인스턴스 ID를 NLB의 대상으로 지정함
* 이 때 올바른 라우팅 메커니즘은?

## 풀이

정답 B

### NBL 의 라우팅 및 IP 주소 요청
* 인스턴스 ID를 사용하여 대상을 지정하는 경우 트래픽은 인스턴스의 기본 네트워크 인터페이스에 지정된 기본 프라이빗 IP 주소를 사용하여 인스턴스로 라우팅됨
* IP 주소를 사용하여 대상을 지정하는 경우 하나 이상의 네트워크 인터페이스에서 프라이빗 IP 주소를 사용하여 인스턴스로 트래픽을 라우팅할 수 있음.
* 이로 인해 여러 어플리케이션이 동일한 포트를 사용 가능

## 3

>회사는 온프레미스 데이터베이스를 AWS 클라우드로 마이그레이션하려고 합니다. 회사의 CTO는 보조 인덱스, 외래 키 및 저장 절차와 같은 복잡한 데이터베이스 구성을 처리할 수 있는 솔루션을 원합니다.
솔루션 아키텍트로서 다음 중 이 사용 사례를 처리하기 위해 결합해야 하는 AWS 서비스는 무엇일까요? (2개 선택)
- AWS 스키마 변환 도구
- AWS 데이터베이스 마이그레이션 서비스
- AWS Snowball 엣지
- 기본 스키마 복사
- AWS Glue

## 요구사항
* 온프레미스 DB -> AWS 마이그레이션
* 보조 인덱스, 외래키 등 복잡한 데이터베이스 구성을 처리할 수 있어야함 

## 풀이

정답 A, B

* 문제에서는 상용 데이터베이스에서 오픈소스 데이터베이스로 변경한다는 말이 없었는데, 풀이를 보니 온프레미스 환경의 데이터베이스이기 때문에 상용 DB에서 오픈소스 DB로 변경하는 것이라고 했다.
* 온프레미스 -> AWS 데이터베이스 마이그레이션에서는 상용에서 오픈소스로 바꾼다는 말을 내포하는 것 같다.
* 따라서 오라클 -> mysql과 같은 마이그레이션일 때 스키마의 및 코드 변환이 필요하므로 스키마 변환 도구도 선택해야 정답이다.


## 4

>한 매체 에이전시는 Amazon S3 버킷에 재생 가능한 자산을 저장합니다. 자산은 처음 며칠 동안 많은 사용자가 액세스하고 일주일 후에 액세스 빈도가 급격히 떨어집니다. 자산은 첫 주 이후부턴 가끔씩 액세스되지만 필요할 때는 즉시 액세스할 수 있어야 합니다. S3 스토리지의 모든 자산을 유지 관리하는 데 드는 비용이 매우 비싸다는 것이 밝혀져 에이전시에서는 최대한 비용을 절감하는 방안을 모색하고 있습니다.
솔루션 아키텍으로서 비즈니스 요구 사항을 충족하면서 스토리지 비용을 절감할 수 있는 방법이 무엇이 있습니까?
- 30일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책을 구성
- 30일 후에 객체를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 수명 주기 정책을 구성
- 7일 후에 객체를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 수명 주기 정책을 구성
- 7일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책을 구성

## 요구사항
* S3 버킷에 자산을 저장하지만 처음 며칠 동안은 사용자가 많고 일주일 후에는 액세스 빈도가 급격히 떨어짐
* 가끔씩 액세스 되더라도 필요할 때는 즉시 액세스할 수 있어야 함
* 가장 비용효율적인 방법

## 풀이

정답 A

### S3 One Zone-IA
* 일반적인 S3 스토리지 클래스는 최소 3개의 AZ에 데이터를 저장하지만, One Zone-IA는 1개의 AZ에 저장하는 대신 비용이 저렴
* S3 스탠다드에서 One Zone-IA로 전환하기 전에 최소 30일의 보관기간이 필요함.

## 5

>한 의료 스타트업은 Amazon S3에 저장된 객체에 대한 규정 준수 및 규제 지침을 시행해야 합니다. 주요 요구 사항 중 하나는 적절한 보호를 제공해 실수로 개체를 삭제하지 않도록 하는 것입니다.
솔루션 아키텍으로서 이러한 지침을 다루기 위해 무엇을 권장하시겠습니까? (2개 선택)
- 버킷에서 버전 관리 활성화
- S3 객체 삭제에 대한 관리자 승인을 받기 위한 프로세스를 수립
- 사용자가 S3 객체를 삭제하는 동안 추가 확인을 제공해야 하도록 AWS S3 콘솔에서 구성 변경
- 버킷에서 MFA 삭제 활성화
- S3 객체 삭제 시 이벤트 트리거를 생성. 이벤트는 IT 관리자에게 이메일을 통해 SNS 알림을 호출


## 풀이

정답 A, D

### 버킷에서 버전관리 활성화
* 객체를 삭제하면 영구적으로 제거되는 대신 Amazon S3가 현재 객체 버전이 되는 삭제 마커를 삽입. 이전 버전으로 언제든지 복원할 수 있음.
* MFA 삭제는 Amazon S3 버킷에서 객체를 영구적으로 삭제하기 전에 보조 인증을 해야 함.

## 6

>애플리케이션 로드 밸런서 배후의 한 소매 회사가 Auto Scaling 그룹에서 배포하는 용도로 Rest API를 개발하였습니다. 이때, API는 사용자 데이터를 DynamoDB에 저장하고 이미지와 같은 다른 Static 컨텐츠들은 S3로 제공되었습니다. 사용 경향을 분석하면 읽기 요청의 90%가 모든 사용자가 공통적으로 액세스하는 데이터에 대한 것으로 나타났습니다.
다음 중 솔루션 아키텍으로서 애플리케이션 성능을 개선하기 위한 가장 효율적인 솔루션은 무엇일까요?
- DynamoDB용 ElastiCache Redis 및 S3용 ElastiCache Memcached 활성화
- DynamoDB용 DynamoDB Accelerator(DAX) 및 S3용 CloudFront 활성화
- DynamoDB용 DAX 및 S3용 ElastiCache Memcached 활성화
- DynamoDB용 ElastiCache Redis 및 S3용 CloudFront 활성화

## 풀이

정답 B

### CloudFront
* CDN(콘텐츠 전송 네트워크) 서비스로 전 세계적으로 static 및 다이내믹 웹 콘텐츠, 영상 스트리밍 및 API를 안전하고 대규모로 제공
* CloudFront에서 데이터를 전달하는 것은 S3에서 사용자에게 직접 전달하는 것보다 더 비용 측면에서 효율적
* CloudFront와 함께 제공하는 컨텐츠를 사용자가 요청하면 해당 요청은 가까운 엣지 로케이션으로 라우팅됩니다. 만약 CloudFront가 요청 파일의 캐시 복사본이 있다면 사용자에 전달해 빠른(낮은 지연 시간) 응답을 제공합니다. 요청한 파일이 아직 캐시되지 않았다면 CloudFront는 오리진에서 검색하는데, 예를 들어 컨텐츠를 저장한 S3 버킷에서 검색합니다.

## 7

>다가오는 프로젝트에 대해 엔지니어링 팀은 Amazon EC2의 사용자 데이터 (user data) 기능의 가능성을 조사하려고 합니다.
다음중 EC2 사용자데이터구성에대한설명으로옳지않은것은무엇일까요? (2개선택)
- 기본적으로 사용자 데이터로 입력된 스크립트에는 실행을 위한 루트 사용자 권한이 없습니다.
- 인스턴스가 실행 중일 때 루트 사용자 자격 증명을 사용하여 사용자 데이터를 업데이트할 수 있습니다.
- 기본적으로 사용자 데이터는 인스턴스를 처음 시작할 때 부팅 주기 동안에만 실행됩니다.
- 기본적으로 사용자 데이터는 EC2 인스턴스가 재시작될 때마다 실행됩니다.
- 기본적으로 사용자 데이터로 입력된 스크립트는 루트 사용자 권한으로 실행됩니다.

## 풀이

정답 C, E

### 사용자 데이터(user data)
* 자동화 구성 작업을 수행하고 인스턴스가 시작된 후 스크립트를 실행하는 데 사용
* 사용자 데이터로 입력된 스크립트는 루트 사용자로 실행되므로 스크립트에 sudo 명령이 필요하지 않음. 또한 생성한 모든 파일은 루트가 소유함.
* 인스턴스가 처음 시작할 때만 부팅 주기에 실행됨. 인스턴스가 재시작될 때마다 실행시키기 위해서는 스크립트를 수정해야 함.

## 8
>Elastic Load Balancer 배후의 EC2 인스턴스에서 호스팅되는 소셜 사진 공유 웹 애플리케이션이 있습니다. 이 앱은 사용자에게 사진 업로드 기능을 제공하고 앱 홈페이지에 리더보드를 표시합니다. 업로드된 사진은 S3에 저장되고 리더보드 데이터는 DynamoDB에 유지됩니다. 이러한 기능을 위해 EC2 인스턴스는 S3와 DynamoDB에 모두 액세스해야 합니다.
솔루션 아키텍트로서 다음 솔루션 중 가장 안전한 옵션은 무엇일까요?
- 사용자 지정 암호화 라이브러리를 통해 AWS 자격 증명을 암호화하고 EC2 인스턴스의 비밀 디렉터리에 저장합니다. 그러면 애플리케이션 코드가 AWS 자격 증명을 안전하게 해독하여 S3 및 DynamoDB에 대한 API 호출을 수행할 수 있습니다.
- EC2 인스턴스의 애플리케이션 코드 내 구성 파일에 AWS 자격 증명(액세스 키 ID 및 보안 액세스 토큰)을 저장합니다. EC2 인스턴스는 이러한 자격 증명을 사용하여 S3 및 DynamoDB에 액세스할 수 있습니다.
- 유효한 IAM 사용자 자격 증명을 사용하여 EC2 인스턴스에서 AWS CLI를 구성합니다. 그런 다음 애플리케이션 코드는 셸 스크립트를 호출하여 AWS CLI를 통해 S3 및 DynamoDB에 액세스할 수 있습니다.
- 인스턴스가 S3 및 DynamoDB에 액세스할 수 있도록 적절한 IAM 역할을 EC2 인스턴스 프로파일에 연결합니다.

## 풀이

정답 D

* EC2에서 실행되는 어플리케이셔은 AWS API 요청시 AWS 자격증명을 포함해야 한다.
* 이 때, 장기증명을(액세스키, 패스워드) EC2 인스턴스 내에 저장하는 것은 각 인스턴스에 자격증명을 안전하게 전달하고, 관리해야 하는 등의 작업이 필요하다.
* IAM 역할을 사용하면 장기증명을 EC2 인스턴스에 저장할 필요 없고, 역할이 임시 자격증명을 제공함. 

## 9 
>금융 서비스 회사는 고주파 거래 시스템을 사용하고 Amazon S3에 로그 파일을 기록하려고 합니다. 시스템은 또한 거의 실시간으로 이러한 로그 파일을 병렬로 읽습니다. 엔지니어링 팀은 거래 시스템이 기존 로그 파일을 덮어쓴 다음 해당 특정 로그 파일을 읽으려고 할 때 발생할 수 있는 데이터 불일치를 해결하려고 합니다.
다음 중 이 시나리오와 관련된 Amazon S3의 기능을 가장 잘 설명하는 옵션은 무엇일까요?
- 프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. Amazon S3는 항상 최신 버전의 객체를 반환합니다.
- 프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. 변경 사항이 완전히 전파될 때까지 Amazon S3는 데이터를 반환하지 않습니다.
- 프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. 변경 사항이 완전히 전파될 때까지 Amazon S3는 이전 데이터를 반환할 수 있습니다.
- 프로세스는 기존 개체를 대체하고 즉시 읽기를 시도합니다. 변경 사항이 완전히 전파될 때까지 Amazon S3에서 새 데이터를 반환할 수 있습니다.

## 풀이

정답 A

* S3는 추가 비용 없이 강력한 쓰기 후 읽기 일관성을 자동으로 제공
* 새 개체를 성공적으로 쓰거나 기존 개체를 덮어쓴 후 후속 읽기 요청은 즉시 최신 버전의 개체를 받음

## 10

>전자 상거래 회사의 엔지니어링 팀은 EC2 인스턴스의 비용 최적화 작업을 하고 있습니다. 팀은 여러 인스턴스 유형에서 온디맨드 및 스팟 인스턴스를 혼합하여 워크로드를 관리하려고 합니다. 그들은 이러한 인스턴스를 혼합하여 Auto Scaling 그룹을 만들고자 합니다.
다음 중 엔지니어링 팀이 이 사용 사례에 대한 인스턴스를 프로비저닝할 수 있는 옵션은 무엇일까요?
- 원하는 규모, 성능 및 비용을 달성하기 위해 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 용량을 프로비저닝하는 시작 템플릿만 사용할 수 있습니다.
- 원하는 규모, 성능 및 비용을 달성하기 위해 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 용량을 프로비저닝하는 시작 구성만 사용할 수 있습니다.
- 원하는 규모, 성능 및 비용을 달성하기 위해 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 용량을 프로비저닝하는 시작 구성 또는 시작 템플릿을 사용할 수 없습니다.
- 원하는 규모, 성능 및 비용을 달성하기 위해 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 용량을 프로비저닝하는 시작 구성 또는 시작 템플릿을 사용할 수 있습니다.

## 풀이

정답 A

### 시작 템플릿 & 시작 구성
* Amazon 머신 이미지(AMI)의 ID, 인스턴스 유형, 키 페어, 보안 그룹 및 시작하는 데 사용하는 기타 파라미터와 같은 인스턴스 구성 정보를 지정
* 시작 템플릿을 사용하면 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하여 여러 인스턴스 유형에 용량을 프로비저닝할 수 있음.
* 시작 구성은 온디맨드 인스턴스와 스팟 인스턴스를 모두 사용하는 여러 인스턴스 유형에 용량을 프로비저닝할 수 없음

